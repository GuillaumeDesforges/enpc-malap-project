\documentclass{article}

% english 
\usepackage[utf8]{inputenc}

% reduced margins
\usepackage{fullpage}

% maths
\usepackage{amsmath}
\usepackage{amssymb}

% algorithms
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}

% metadata
\title{Stochastic Dual Coordinate Descent}
\author{Guillaume Desforges \& MichaÃ«l Karpe \& Matthieu Roux}
\date{June 14th 2018}

% custom commands
\newcommand{\abs}[1]{\left|#1\right|}
\newcommand{\norm}[1]{\left\|#1 \right\|}

% custom display
\setlength{\parskip}{0.3em}
\setlength{\parindent}{0em}

\begin{document}

\maketitle

%=================================================================================================
\section*{Introduction}

% Context
\hspace{2em}
In machine learning, the process of fitting a model to the data requires to solve an optimization problem.
The difficulty resides in the fact that this optimization quickly becomes very complex when dealing with real problems.
The Stochastic Gradient Descent (SGD) is a very popular algorithm to solve those problems because it has good convergence guaranties.
Yet, the SGD does not have a good stopping criteria, and its solutions are often not accurate enough.

% General problem studied, general methodology
\hspace{2em}
The Stochastic Dual Coordinate Ascent tries to solves the optimization problem by solving its dual problem.
Instead of optimizing the weights, we optimize a dual variable from which we can compute the weights and thus solve the former.
This method can give good results for specific problems : for instance, solving the dual problem of the SVM has proven to be effective and to give interesting results, with a linear convergence in some cases.

% Focus and goal of the work presented
\hspace{2em}
In this report, we compile the key theoretical points necessary to have a global understanding of the SDCA.

% Structure of the report
\hspace{2em}
First we introduce the general forms of the machine learning problems we want to use SDCA on and how we get to the dual form.
We introduce the duality gap and how it is useful.
Then we study computational performances of the method by trying to apply SDCA on concret problems.
Finally we conclude on SDCA strengths and weaknesses.

\paragraph{Note} \textit{We especially added experimentations since the presentation of our poster.}

\newpage
%=================================================================================================
\section{Methods}
% 3 pages
% (a) [DONE] ...... specific problem studied
% (b) [TODO?] ..... related work
% (c) [DONE] ...... model, main idea
% (d) [IRRELEVANT]  specific methodology
% (e) [DONE] ...... algorithms

\subsection{Dual problem}

Since a machine learning problem is an optimization problem, one can try to write its dual.

As an example, we present a dual problem for the logistic regression.
The multiclass logistic regression, with the cross entropy loss, is a generalization of the binary logistic regression that requires more work, so for now we stick to the binary problem which is interesting enough.

We use the following usual notations :
\begin{itemize}
	\item[] $X \in \mathbf{X} = \mathbb{R}^p$ the random variable for the description space;
	\item[] $Y \in \mathbf{Y} = \{-1,1\}$ the random variable for the label.
\end{itemize}

We recall that the model is the following :
\begin{equation}
	\frac{\mathbb{P}(y=1 | X=x)}{\mathbb{P}(y=-1 |X=x)} = w^T x, \quad w \in \mathbb{R}^p
\end{equation}

We want to find $w$ so that it maximizes the likelihood, or log-likelihood, with a term of regularization:
\begin{equation}
	\min_w C \sum_i \log(1 + e^{-y_iw^Tx_i)}  + \frac{1}{2} w^Tw
\end{equation}

In order to get the dual problem, we rewrite it with an artificial constraint $z_i = y_iw^Tx_i$, and we have the following lagrangian :
\begin{equation}
	\mathcal{L}(w, z, \alpha) = \sum_i (C \log(1+z_i) + \alpha_i z_i) - \sum_i \alpha_i e^{-z_i} + \frac{1}{2}w^Tw 
\end{equation}

We note $w^*$ and $z^*$ the variables solution of the optimization problem
\begin{equation}
	\min_{w, z} \mathcal{L}(w, z, \alpha) = \mathcal{L}(w^*, z^*, \alpha) = \psi(\alpha) 
\end{equation}

Where, $w^* = \sum_i \alpha_i y_i x_i$.

It leads to the following dual problem :
\begin{equation}
	\begin{aligned}
		& \max_{\alpha} & &\sum_{i \in I} (-\alpha_i \log(\alpha_i) - (C-\alpha_i) \log(C - \alpha_i)) - \frac{1}{2} \alpha^TQ\alpha\\
		& s.t.          & &I = \{i,\ 0 < \alpha_i < C \}\\
		&               & &0 \leq \alpha_i \leq C
	\end{aligned}
\end{equation}

We note $Q = (Q_{ij})_{i,j}$ where $Q_{ij} = y_i x_i^T x_j y_j$. It appears that the optimization problem is fully parametrized by the scalar products of the data.

\subsection{A more generic form}

If we consider now a generic loss function $\phi$, either L-Lipschitz or ($1/\gamma$)-smooth, we can rewrite the optimization problem as follow, where P refers to primal form :
\begin{equation}
    \min_{w \in \mathbb{R}^d} P(w) \quad \text{ where } P(w) = \left[ \dfrac{1}{n} \sum_{i=1}^n \phi_i(w^\top x_i) + \dfrac{\lambda}{2}\norm{w}^2 \right]
    \label{primal}
\end{equation}
with solution $w^{*} = \arg \min_{w \in \mathbb{R}^d} P(w)$.

Let's now introduce the convex conjugate, a very useful tool in the dual space. It is defined as follow $\phi_i$ : $\phi_i^{*}(u) = \max_z (zu-\phi_i(z))$. In the case $\phi_i$ is (1/$\gamma$)-smooth, its convex conjugate $\phi_i^*$ is $\gamma$-strongly convex. We are now able to have a compact notation for the dual problem :
\begin{equation}
    \max_{\alpha \in \mathbb{R}^n} D(\alpha) \quad \text{ where } D(\alpha) = \left[ \dfrac{1}{n} \sum_{i=1}^n -\phi_i^{*}(-\alpha_i) - \dfrac{\lambda}{2}\norm{\dfrac{1}{\lambda n}\sum_{i=1}^n \alpha_ix_i}^2 \right]
    \label{dual}
\end{equation}
with solution $\alpha^{*} = \arg \max_{a \in \mathbb{R}^n} D(\alpha)$.

Some loss functions used in the report are described in the table in appendix \ref{appendix-losses}.

\subsection{SDCA principle}

\hspace{2em}
When optimizing with the standard SGD, the learning rate $\epsilon$ is not adaptative, and it can be more or less complicated to find a good one, which could provide good properties of convergence.

\hspace{2em}
With DCA, instead of ascending in the direction of the gradient with a fixed increment, it maximizes the objective value on one dual coordinate at once.
The idea is then to repeat the operation on all dual coordinate so that it converges to the maximum of the objective function.
We can then give it stochastic properties by chosing randomly the coordinate to optimize at each iteration : it is then the SDCA.

\subsection{Duality Gap}

SDCA optimizes the dual problem, which is not the primal problem.
This difference is called the duality gap, which we explain here.

Let $x_1, \dots, x_n \in \mathbb{R}^d$, $\phi_1, \dots, \phi_n$ scalar convex functions, $\lambda > 0$ regularization parameter.

Let us focus on the following optimization problem:

\begin{equation}
	\min_{w \in \mathbb{R}^d} P(w) \quad \text{ where } P(w) = \left[ \dfrac{1}{n} \sum_{i=1}^n \phi_i(w^\top x_i) + \dfrac{\lambda}{2}\norm{w}^2 \right]
	\label{primal}
\end{equation}
with solution $w^{*} = \arg \min_{w \in \mathbb{R}^d} P(w)$.

Moreover, we say that a solution $w$ is $\epsilon_P$-sub-optimal if $P(w) - P(w^{*}) \leq \epsilon_P$.

We analyze here the required runtime to find an $\epsilon_P$-sub-optimal solution using SDCA.

Let $\phi_i^{*} : \mathbb{R} \rightarrow \mathbb{R}$ be the convex conjugate of $\phi_i$ : $\phi_i^{*}(u) = \max_z (zu-\phi_i(z))$.

The dual problem of \eqref{primal} is defined as follows:
\begin{equation}
	\max_{\alpha \in \mathbb{R}^n} D(\alpha) \quad \text{ where } D(\alpha) = \left[ \dfrac{1}{n} \sum_{i=1}^n -\phi_i^{*}(-\alpha_i) - \dfrac{\lambda}{2}\norm{\dfrac{1}{\lambda n}\sum_{i=1}^n \alpha_ix_i}^2 \right]
	\label{dual}
\end{equation}
with solution $\alpha^{*} = \arg \max_{a \in \mathbb{R}^n} D(\alpha)$.

% cette phrase ne veut rien dire, il faut la reformuler
Let $w(\alpha) = \frac{1}{\lambda n} \sum_{i=1}^n \alpha_ix_i$.
We have $w(\alpha^{*}) = w^{*}$, $P(w^{*}) = D(\alpha^{*})$, $\forall (w,\alpha), P(w) = D(\alpha)$ due to classic optimization results.

We define the duality gap : $P(w(\alpha)) - P(w^{*})$

\subsection{The SDCA algorithm}

The SDCA algorithm is as follow.

\begin{algorithm}
	\caption{Procedure SCDA with averaging option}
	\begin{algorithmic}
		\Procedure{SCDA}{$\alpha^{(0)},\phi, T_0$}
		\State $w^{(0)} \gets w(\alpha^{(0)})$
		\For{$t = 1, \dots, T$} %FOR
		\State Randomly pick $i$
		\State $\Delta \alpha_i \gets \arg \max -\phi^{*}_i(-(\alpha_i^{(t-1)}+\Delta \alpha_i))-\frac{\lambda n}{2}\norm{w^{(t-1)}+(\lambda n)^{-1}\Delta \alpha_i x_i}^2$ \qquad \qquad \qquad \qquad \qquad (*)
		\State $\alpha^{(t)} \gets \alpha^{(t-1)} + \Delta \alpha_i e_i$
		\State $w^{(t)} \gets w^{(t-1)} + (\lambda n)^{-1} \Delta \alpha_i x_i$
		\EndFor
		\State \textbf{return} $\overline{w} = \frac{1}{T-T_0} \sum_{i = T_0+1}^T w^{(t-1)}$
		\EndProcedure
	\end{algorithmic}
\end{algorithm}

$T_0$ can be chosen between $1$ to $T$, and is generally chosen equal to $T/2$.
However, in pratice, these parameters are not required as the duality gap is used to terminate the algorithm.

\subsection{Stopping time}

We consider the following assumptions: $\forall i, \norm{x_i} \leq 1$, $\forall (i,a), \phi_i(a) \geq 0$ and $\forall i, \phi_i(0) \leq 1$.

Under these assumptions, we have the following theorem:

% reference du theoreme ?
\paragraph{Theorem} Consider Procedure SDCA with $\alpha^{(0)} = 0$.
Assume that $\forall i, \phi_i$ is $L$-Lipschitz (resp.
$(1/\gamma)$-smooth).
To obtain an expected duality gap of $\mathbb{E}[P(\overline{w})-D(\overline{\alpha})] \leq \epsilon_P$, it suffices to have a total number of iterations of
\begin{equation}
	T \geq n + \max\left(0, \left\lceil n \log \left(\dfrac{\lambda n}{2 L^2} \right) \right\rceil \right) + \dfrac{20 L^2}{\lambda \epsilon_P} \quad \left( \text{resp. } T > \left(n + \dfrac{1}{\lambda \gamma} \right) \log \left[ \dfrac{1}{(T-T_0)\epsilon_P} \left(n + \dfrac{1}{\lambda \gamma} \right) \right] \right)
\end{equation}

\subsection{Why SDCA over SGD ?}

SGD finds an $\epsilon_P$-sub-optimal solution in time $O(1/(\lambda \epsilon_P))$.
This runtime does not depend on $n$ and therefore is favorable when $n$ is very large.
However, the SGD approach has several disadvantages:

\begin{enumerate}
    \item it does not have a clear stopping criterion;
    \item it tends to be too aggressive at the beginning of the optimization process, especially when $\lambda$ is very small;
    \item while SGD reaches a moderate accuracy quite fast, its convergence becomes rather slow when we are interested in more accurate solutions.
\end{enumerate}


\newpage
%=================================================================================================
\section{Experiments}
% 2 pages
% (a) Description of the dataset(s) considered / general problem associated with the data \\
% (b) Description of the protocol of the experiments (setting of the hyperparameters/cross-validation procedure/evaluation methodology) \\
% (c) Factual description of the type of results reported (explanation pertaining to the Figures, tables, etc) \\
% (d) Interpretation and discussion of the results (comparison with the baselines, advantages of each algorithm, etc) \\

\subsection{Datasets}
\subsection{Protocol}
\subsection{Results}
\subsubsection{Raw results}
\subsubsection{Interpretations}

\newpage
%=================================================================================================
\section*{Conclusion}
% 1/2 page
% (a) summary \\
% (b) main conclusions and take home messages \\
% (c) Remaining questions/ future directions (only if relevant) \\


\newpage
%=================================================================================================
\appendix

\section{Losses used}
\label{appendix-losses}

\begin{center}
	\begin{table}[H]
		\centering

		\begin{tabular}{|c|}
			\hline

			\textbf{Squared loss:}\\[1.3em]
			$\phi_i(a) = (a-y_i)^2$\\[1.3em]
			$\phi_i^{*}(-a) = -ay_i+a^2/4$\\[1.3em]
			$\Delta \alpha_i = \dfrac{y_i-x_i^\top w^{(t-1)}-0.5\alpha_i^{(t-1)}}{0.5+\norm{x_i}^2/(\lambda n))}$\\[1.3em]

			\hline

			\textbf{Absolute deviation loss:}\\[1.3em]
			$\phi_i(a) = \abs{a-y_i}$ \\[1.3em]
			$\phi_i^{*}(-a) = -ay_i$, $a \in [-1,1]$\\[1.3em]
			$\Delta \alpha_i = \max \left( 1, \min \left( 1, \dfrac{y_i-x_i^\top w^{(t-1)}}{\norm{x_i}^2/(\lambda n)} + \alpha_i^{(t-1)} \right) \right) - \alpha_i^{(t-1)}$\\[1.3em]
			
			\hline

			\textbf{Log loss:}\\[1.3em]
			$\phi_i(a) = \log(1+\exp(-y_ia))$\\[1.3em]
			$\phi_i^{*}(-a) = -ay_i\log(ay_i) + (1-ay_i)\log(1-ay_i)$\\[1.3em]
			$\Delta \alpha_i = \dfrac{(1+\exp(x_i^\top w^{(t-1)}y_i))^{-1}y_i-\alpha_i^{(t-1)}}{\max(1,0.25+\norm{x_i}^2/(\lambda n))}$\\[1.3em]

			\hline

			\textbf{($\gamma$-smoothed) Hinge loss:}\\[1.3em]
			$\phi_i(a) = \max\{0,1-y_ia\}$\\[0.3em]
			$\phi_i^{*}(-a) = -ay_i + \gamma a^2/2$, $ay_i \in [0,1]$\\[1.3em]
			$\Delta \alpha_i = y_i \max \left( 0, \min \left( 1, \dfrac{1-x_i^\top w^{(t-1)} y_i-\gamma \alpha_i^{(t-1)}y_i}{\norm{x_i}^2/(\lambda n)+\gamma} + \alpha_i^{(t-1)} y_i \right) \right) - \alpha_i^{(t-1)}$\\[1.3em]

			\hline
		\end{tabular}

		\caption{Used loss functions, convex conjugates and closed form of solutions of problem (*).}
		\label{dataset}
	\end{table}
\end{center}

$\Delta \alpha_i$ is the notation we use to represent the increment to add to $\alpha_i$ (one coordinate, at a given iteration) to maximize the objective function with respect to that coordinate.


\end{document}

